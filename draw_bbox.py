{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"draw_bbox.py","provenance":[],"collapsed_sections":[],"mount_file_id":"1hBrQbCBA-3Hj5UpqH8HJDAki_uw1TOjj","authorship_tag":"ABX9TyOf/mIhrr0zprZA9LhfDsSi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"KwdP8nBjLBYr"},"source":["#using https://github.com/ivder/YoloBBoxChecker.git and https://github.com/pjreddie/darknet/issues/723#issuecomment-803872581\n","\n","import cv2\n","import colorsys\n","import os\n","from os import walk, getcwd\n","import numpy as np\n","import shutil\n","from pathlib import Path\n","\n","\"\"\" Configure Paths\"\"\"\n","home_path = str(Path(__file__).absolute()).rstrip('draw_bbox.py')\n","model_resolution_epochs = input (\"Please input <model>_<resolution>_<epochs>: \")\n","dataset_folder = input(\"Please input dataset folder name: \")\n","text_file_path = home_path + str(dataset_folder) + '/results' + '_' + str(model_resolution_epochs) + '.txt'\n","out_dir = home_path + str(dataset_folder) + '/detection_results/' + str(model_resolution_epochs) + '/'  #generate new folder for each ver\n","print (out_dir)\n","\n","'''\n","This script is meant to read a yolo log file with batch inferred results\n","and draw predicted bounding boxes on the source pictures. Run it with\n","hardcoded paths that you NEED TO MODIFY, READ THE SCRIPT THROUGH.\n","\n","The file needed as input can be obtained by running this command:\n","./darknet detector test PATH/obj.data PAestTH/yolov4.cfg PATH/yolov4.weights -dont_show -ext_output < PATH/test.txt > results_yo.txt\n","\n","Where test.txt is a textfile with the absolute path of each of the images\n","to be batch-inferred and results_yo.txt is the output that will be generated\n","by darknet. Inside this file, each predicted image should look something \n","like this, adjust file scraping to if neccesary for further releases:\n","\n","\"\"\"\n","Enter Image Path:  Detection layer: 82 - type = 28 \n"," Detection layer: 94 - type = 28 \n"," Detection layer: 106 - type = 28 \n","/content/drive/MyDrive/Dataset_2000/0001d48938a45d49_jpg.rf.2490cc9c42e5c21a7b856426039a6ebc.jpg: Predicted in 44.825000 milli-seconds.\n","Closed Door: 41%\t(left_x:  -32   top_y:   11   width:  728   height:  468)\n","Closed Door: 33%\t(left_x:  257   top_y:   -5   width:  777   height:  493)\n","Person: 100%\t(left_x:  618   top_y:  293   width:   74   height:  249)\n","Enter Image Path:  Detection layer: 82 - type = 28 \n","\"\"\"\n"," \n","'''\n","#convert yolo coords to format required for plotting\n","def convert(size,x,y,w,h):\n","    box = np.zeros(4)\n","    dw = 1./size[0]\n","    dh = 1./size[1]\n","    x = x/dw\n","    w = w/dw\n","    y = y/dh\n","    h = h/dh\n","    box[0] = x-(w/2.0)\n","    box[1] = x+(w/2.0)\n","    box[2] = y-(h/2.0)\n","    box[3] = y+(h/2.0)\n","\n","    return (box)\n","\n","# create ouput path if doesnt exist + init counter 'idx'\n","try: \n","  out_path = Path (out_dir)\n","  out_path.mkdir(parents=True)\n","  print (\"directory created\")\n","except: \n","  print ('directory exists')\n","idx = False #used as flag for image out\n","\n","# required format params for drawing annotations\n","thickness = 2\n","font = cv2.FONT_HERSHEY_SIMPLEX\n","fontScale = 0.9\n","# read the output of the YOLO log to load predictions\n","with open(text_file_path, 'r') as file:\n","  for line in file.readlines():\n","    if home_path in line:\n","      # load file as cv2 image from text file\n","      picpath = line.split(':')[0]\n","      print (picpath)\n","      pic = cv2.imread(picpath)\n","      #reading ground truth file    \n","      gt_path = picpath.rstrip('.jpg\\n') + '.txt'\n","      gt_file = open(gt_path, \"r\")\n","      gt_box = gt_file.readlines()\n","      #adding gt to file      \n","      for id, line in enumerate(gt_box):\n","        value = line.split()\n","        x=y=w=h=cls= None\n","        cls = value[0]\n","        x = float(value[1])\n","        y = float(value[2])\n","        w = float(value[3])\n","        h = float(value[4])\n","\t\n","        img_h, img_w = pic.shape[:2]\n","        bb = convert((img_w, img_h), x,y,w,h)\n","        pic = cv2.rectangle(pic, (int(round(bb[0])),int(round(bb[2]))),(int(round(bb[1])),int(round(bb[3]))),(0,255,0),2)\n","\n","        # when a prediction is recorded, add the bbox to the current image\n","    if '%' in line:\n","    # read the class + confidence score as title\n","      title = line.split('%')[0] + '%'\n","       \n","            # use the class initial to define color\n","      hue = ord(title[0]) - (100.5 - ord(title[0])) * 15\n","      color = tuple(255 * i  for i in colorsys.hsv_to_rgb(hue/360.0, 1, 1))\n","            \n","      # work out where to draw the bounding box depending on output img size\n","      x1, y1, w, h = [int(abs(int(i))) for i in line[:-2].replace('-','').split() if i.isdigit()]\n","            \n","      # actually overwrite the picture with box + title\n","      pic = cv2.rectangle(pic, (x1, y1), (x1 + w, y1 + h), color, thickness)\n","      pic = cv2.putText(pic, title, (x1, y1), font, fontScale, color, thickness, cv2.LINE_AA)\n","\n","    if \"Enter Image\" in line:\n","      if idx == False: #idx used as flag here, to get past the first \n","        idx = True\n","      elif idx == True:\n","        cv2.imwrite(os.path.join(out_dir, picpath.lstrip(home_path + str(dataset_folder) + '/')),pic)\n","        print (\"image saved at \" + os.path.join(out_dir, picpath.lstrip(home_path + str(dataset_folder) + '/')))\n","\n","\n"],"execution_count":null,"outputs":[]}]}